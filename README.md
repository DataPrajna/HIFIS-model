# HIFIS-v2 Model

The purpose of this project is to investigate the efficacy of a machine
learning solution to assist in identifying individuals at risk of
chronic homelessness. A model prototype was built for the City of
London, Ontario, Canada. This repository contains the code used to train
a neural network model to classify clients in the city's HIFIS database
as either at risk or not at risk of chronic homelessness within a
specified predictive horizon. In an effort to comply with the Canadian
federal government's
[Directive on Automated Decision-Making](https://www.tbs-sct.gc.ca/pol/doc-eng.aspx?id=32592),
this repository applies interpretability methods to explain the model's
predictions. to This repository is intended to serve as a template for
other municipalities who wish to explore the application of this model
in their own locales.

## Getting Started
1. Clone this repository (for help see this
   [tutorial](https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository)).
2. Run [_Ryans_query.sql_](Ryans_query.sql) and rename the resulting csv
   file as _"HIFIS_Clients.csv"_.
3. Place _HIFIS_Clients.csv_ in the _data/raw/_ folder.
4. Check that your features match in config.yml
5. Execute [_preprocess.py_](src/data/preprocess.py) to transform the
   data into the format required by the machine learning model.
6. Execute [_train.py_](src/train.py) to train the neural network model
   on your preprocessed data.
7. Execute [_lime_explain.py_](src/interpretability/lime_explain.py) to
   generate interpretable explanations for the model's predictions on
   the test set.

## Project Structure
The project looks similar to the directory structure below. Disregard
any _.gitkeep_ files, as they exist solely to demonstrate preferred
project organization.

```
├── data
│   ├── interpretability          <- Generated feature information
│   ├── processed                 <- Products of preprocessing
│   ├── raw                       <- Raw data from SQL query
│   └── transformers              <- Serialized sklearn transformers
|
├── documents
|   └── images                    <- Visualizations of model performance
├── results
│   ├── experiments               <- Experiment results
│   ├── logs                      <- TensorBoard logs
│   ├── models                    <- Trained model weights
│   └──  predictions              <- Model predictions and explanations
|
├── src
│   ├── custom                    <- Custom TensorFlow components
|   |   └── metrics.py            <- Definition of custom TensorFlow metrics
│   ├── data                      <- Data processing
|   |   └── preprocess.py         <- Preprocessing script
│   ├── interpretability          <- Model interpretability scripts
|   |   └── lime_explain.py       <- Script for generating LIME explanations
│   ├── models                    <- TensorFlow model definitions
|   |   └── models.py             <- Script containing model definition
|   ├── visualization             <- Visualization scripts
|   |   └── visualize.py          <- Script for visualizing model performance metrics
|   ├── horizon_search.py         <- Script for comparing different prediction horizons
|   ├── predict.py                <- Script for prediction on raw data using trained models
|   └── train.py                  <- Script for training model on preprocessed data
|
├── .gitignore                    <- Files to be be ignored by git.
├── config.yml                    <- Values of several constants used throughout project
├── config_private.yml            <- Private information, e.g. database keys (not included in repo)
├── LICENSE                       <- Project license
└── README.md                     <- Project description
```

## Project Config
Many of the components of this project are ready for use on your HIFIS
data. However, this project contains several configurable variables that
are defined in the project config file: [config.yml](config.yml). When
loaded into Python scripts, the contents of this file become a
dictionary through which the developer can easily access its members.

For user convenience, the config file is organized into major steps in
our model development pipeline. Many fields need not be modified by the
typical user, but others may be modified to suit the user's specific
goals. A summary of the major configurable elements in this file
follows.

#### PATHS
- **RAW_DATA**: Path to .csv file generated by running
  _ClientExport.sql_
#### DATA
- **N_WEEKS**: Predictive horizon in weeks
- **GROUND_TRUTH_DATE**: Date at which to compute ground truth (i.e.
  state of chronic homelessness) for clients
- **CHRONIC_THRESHOLD**: Number of stays per year for a client to be
  considered chronically homeless
- **FEATURES_TO_DROP_FIRST**: Features you would like to exclude
  entirely from the model. For example, after running LIME, we realized
  that features like EyeColour were polluting the data, so we decided to
  take it out....
#### NN
- **MODEL1**: Contains definitions of configurable hyperparameters
  associated with the model architecture
#### TRAIN
- **TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT**: Fraction of the data allocated
  to the training, validation and test sets respectively
- **EPOCHS**: Number of epochs to train the model for
- **BATCH_SIZE**: Mini-batch size during training
- **POS_WEIGHT**: Coefficient to multiply the positive class' weight by
  during computation of loss function. Negative class' weight is
  multiplied by (1 - POS_WEIGHT). Increasing this number tends to
  increase recall and decrease precision.
- **IMB_STRATEGY**: Class imbalancing strategy to employ. In our
  dataset, the ratio of positive to negative ground truth was very low,
  propmting the use of these strategies. Set either to 'class_weight',
  'random_oversample', 'smote', or 'adasyn'.
- **METRIC_MONITOR**: The metric to monitor when training multiple
  models serially (i.e. the _'multi_train'_ experiment in
  [_train.py_](src/train.py)
- **NUM_RUNS**: The number of times to train a model in the
  _'multi_train'_ experiment
- **THRESHOLDS**: A single float or list of floats in range [0, 1]
  defining the classification threshold. Affects precision and recall
  metrics.
- **HP**: Parameters associated with random hyperparameter search
  - **METRICS**: List of metrics on validation set to monitor in
    hyperparameter search
  - **COMBINATIONS**: Number of random combinations of hyperparameters
    to try in hyperparameter search
  - **REPEATS**: Number of times to repeat training per combination of
    hyperparameters
  - **RANGES**: Ranges defining possible values that
    hyperparameters may take. Be sure to check
    [_train.py_](src/train.py) to ensure that your ranges are defined
    correctly as real or discrete intervals.
#### LIME
- **KERNEL_WIDTH**: Affects size of neighbourhood around which LIME
  samples for a particular example
- **FEATURE_SELECTION**: The strategy to select features for LIME
  explanations. Read the LIME creators'
  [documentation](https://lime-ml.readthedocs.io/en/latest/lime.html)
  for more information.
- **NUM_FEATURES**: The number of features to include in a LIME
  explanation
  **NUM_SAMPLES**: The number of samples used to fit a linear model when
  explaining a prediction using LIME
#### PREDICTION
- **THRESHOLD**: Classification threshold for prediction
- **CLASS_NAMES**: Identifiers for the classes predicted by the neural
  network as included in the prediction spreadsheet.

