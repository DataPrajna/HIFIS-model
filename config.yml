# Relevant file/directory paths
PATHS:
  RAW_DATA: 'data/raw/HIFIS_Clients.csv'
  RAW_SPDAT_DATA: 'data/raw/SPDATS.json'
  PROCESSED_DATA: 'data/processed/HIFIS_Processed.csv'
  PROCESSED_OHE_DATA: 'data/processed/HIFIS_Processed_OHE.csv'
  GROUND_TRUTH: 'data/processed/GroundTruth.csv'
  DATA_INFO: './data/interpretability/data_info.yml'
  MODEL_WEIGHTS: 'results/models/model.h5'
  MODEL_TO_LOAD: 'results/models/model.h5'
  IMAGES: 'documents/generated_images/'
  LOGS: 'results\\logs\\'
  HORIZON_SEARCH: 'results/experiments/horizon_search'
  LIME_EXPERIMENT: 'results/experiments/lime_experiment'
  TRAIN_SET: 'data/processed/Train_Set.csv'
  TEST_SET: 'data/processed/Test_Set.csv'
  SCALER_COL_TRANSFORMER: 'data/transformers/scaler_col_transformer.bin'
  ORDINAL_COL_TRANSFORMER: 'data/transformers/ordinal_col_transformer.bin'
  OHE_COL_TRANSFORMER_MV: 'data/transformers/ohe_col_transformer_mv.bin'
  OHE_COL_TRANSFORMER_SV: 'data/transformers/ohe_col_transformer_sv.bin'
  LIME_EXPLAINER: './data/interpretability/lime_explainer.pkl'
  BULK_PREDICTIONS: './results/predictions/predictions'
  TRENDING_PREDICTIONS: './results/predictions/trending_predictions.csv'

# Constants pertaining to data structure
DATA:
  N_WEEKS: 26
  GROUND_TRUTH_DATE: 'today'
  CHRONIC_THRESHOLD: 180
  INCLUDE_SPDATS: true
  FEATURES_TO_DROP_FIRST: ['OrganizationID','MovedInDate','HealthIssueMedicationName','OtherMedications','DietCatetory','FoodType',
                           'ConsentType','ClientHeightCM','EyeColour','HairColour','ProvinceOfBirth','CityOfBirth','CountryOfBirth',
                           'ServiceProvider']
  IDENTIFYING_FEATURES_TO_DROP_LAST: ['ServiceID','FamilyID','MonthlyAmount','DOB']
  TIMED_FEATURES_TO_DROP_LAST: ['ServiceEndDate','ExpenseStartDate','ExpenseEndDate','IncomeStartDate',
                           'IncomeEndDate','HealthIssueStart','HealthIssueEnd','LifeEventStartDate','LifeEventEndDate','SPDAT_Date',
                           'ContributingFactorDateStart','ContributingFactorDateEnd','BehavioralRiskFactorDateStart','BehavioralRiskFactorDateEnd',
                           'EducationStartDate','EducationEndDate','WatchConcernDateStart','WatchConcernDateEnd']
  TIMED_EVENT_FEATURES:
    ExpenseStartDate: ['ExpenseType', 'Expensefrequency', 'ExpenseAmount', 'IsEssentialYN']
    IncomeStartDate: ['IncomeType', 'MonthlyAmount']
    HealthIssueStart: ['HealthIssue', 'HealthIssueMedicationName', 'OtherMedications', 'DiagnosedYN','SelfReportedYN', 'SuspectedYN']
    ContributingFactorDateStart: ['ContributingFactor']
    BehavioralRiskFactorDateStart: ['BehavioralFactor', 'Severity']
    LifeEventStartDate: ['LifeEvent']
    SPDAT_Date: ['TotalScore','SPDAT_Type','PreScreenPeriod']
    WatchConcernDateStart: ['WatchConcern']
  TIMED_SERVICE_FEATURES: ['Stay', 'Case Management', 'Housing', 'Housing Subsidy', 'Storage']
  COUNTED_SERVICE_FEATURES: ['Reservations', 'Turnaways', 'Food Bank', 'Goods and Services']
  NONCATEGORICAL_FEATURES: ['ServiceID','ClientID','FamilyID','ServiceStartDate', 'ServiceEndDate','CurrentAge','ClientHeightCM',
    'ClientWeightKG','MonthlyAmount', 'ExpenseAmount','SPDAT_Date','TotalScore']
  CATEGORICAL_FEATURES: ['ConsentType', 'RelationshipType', 'Gender', 'AboriginalIndicator', 'Citizenship', 'VeteranStatus', 'CountryOfBirth',
    'ProvinceOfBirth', 'CityOfBirth', 'GeoRegion', 'HairColour', 'EyeColour', 'ServiceType', 'OrganizationName', 'ReasonForService',
    'CurrentlyHoused', 'IncomeType', 'ExpenseType', 'Expensefrequency', 'IsEssentialYN', 'EducationLevel', 'HealthIssue', 'DiagnosedYN',
    'SelfReportedYN', 'SuspectedYN', 'HealthIssueMedicationName', 'OtherMedications', 'WatchConcern', 'ContributingFactor', 'BehavioralFactor',
    'Severity', 'LifeEvent', 'DietCatetory', 'FoodType', 'AvoidInDiet', 'SPDAT_Type', 'ServiceProvider', 'PreScreenPeriod']
  TIME_PAIRED_FEATURES:
    -
      NAME: 'Service'
      START: 'ServiceStartDate'
      END: 'ServiceEndDate'


# Neural network models
NN:
  MODEL1:
    NODES:
      DENSE0: 80
      DENSE1: 60
    LAYERS: 2
    L2_LAMBDA: 0.03
    DROPOUT: 0.5
    LR: 0.0003

# Training
TRAIN:
  TRAIN_SPLIT: 0.8
  VAL_SPLIT: 0.1
  TEST_SPLIT: 0.1
  EPOCHS: 300
  BATCH_SIZE: 128
  POS_WEIGHT: 0.6
  IMB_STRATEGY: 'class_weight'  # One of {'class_weight', 'random_oversample', 'smote', 'adasyn'}
  EXPERIMENT_TYPE: 'single_train' # One of {'single_train', 'multi_train', 'hparam_search'}
  METRIC_MONITOR: 'recall'
  NUM_RUNS: 10
  THRESHOLDS: 0.5   # Can be changed to list of values in range [0, 1]
  HP:
    METRICS: ['accuracy', 'loss', 'recall', 'precision']
    COMBINATIONS: 60
    REPEATS: 2
    RANGES:
      NODES0: [60, 80, 100, 120, 140]
      NODES1: [40, 60, 80, 100]
      LAYERS: [2, 3, 4]
      DROPOUT: [0.5, 0.5]
      LR: [-3.5, -3.5]  # Logarithmic scale (10^x)
      OPTIMIZER: ['adam']
      BETA_1: [-1.0, -1.0]  # 1st moment for Adam. Log scale (1 - 10^x)
      BETA_2: [-3.0, -3.0]  # 2nd moment for Adam. Log scale (1 - 10^x)
      L2_LAMBDA: [-1.5, -1.5]   # Logarithmic scale (10^x)
      BATCH_SIZE: [128, 128]
      POS_WEIGHT: [0.6, 0.6]  # Weight multiplier for positive class
      IMB_STRATEGY: ['class_weight']

# LIME explanations
LIME:
  KERNEL_WIDTH: 2.5
  FEATURE_SELECTION: 'lasso_path'
  NUM_FEATURES: 15
  NUM_SAMPLES: 85000
  MIN_DISPLAY_WEIGHT: 0.005
  SP:
    SAMPLE_SIZE: 50
    NUM_EXPLANATIONS: 10

# Predictive horizon search experiment
HORIZON_SEARCH:
  N_MIN: 0
  N_MAX: 52
  N_INTERVAL: 4
  RUNS_PER_N: 10

# Bulk predictions on raw data
PREDICTION:
  THRESHOLD: 0.5
  CLASS_NAMES: {0: 'not at risk', 1: 'at risk'}